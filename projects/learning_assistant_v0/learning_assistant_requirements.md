---
Project: Learning Assistant
Type: Requirements
Date: 2025-07-17
---

# Learning Assistant V0 Requirements

## Overview
The Learning Assistant V0 is an AI-powered tool for thinkheads.ai, designed to support personal AI/ML/DL learning through personalized resource suggestions, note-taking, and interactive exercises. Integrated with the AI-driven website, it uses Ollama for LLM-driven features and PostgreSQL for data storage. This document outlines functional and non-functional requirements to ensure the tool supports skill development and portfolio enhancement, designed for solo development within a 20-hour/week schedule, using Proxmox (Ollama, PostgreSQL) and Linode (APIs), per **3.2 Project_Roadmap.md**.

## Functional Requirements
| ID  | Requirement Description                              | Priority | Acceptance Criteria                                      |
|-----|-----------------------------------------------------|----------|---------------------------------------------------------|
| FR01 | **Resource Suggestions**: Provide LLM-driven suggestions for AI/ML/DL resources based on user queries. | High     | - Users input learning topics via web interface.<br>- Ollama (RAG) suggests relevant resources (e.g., papers, tutorials).<br>- Response time <2s for 95% of queries.<br>- Suggestions include at least 3 resources with links. |
| FR02 | **Note-Taking System**: Allow users to save and export notes from learning sessions. | High     | - Notes stored in PostgreSQL, exportable as markdown.<br>- Supports 100+ notes per user.<br>- Accessible via web interface.<br>- Export completes in <5s. |
| FR03 | **Reinforcement Learning Exercises**: Offer interactive AI/ML exercises with feedback. | Medium   | - Exercises generated by LLM, stored in PostgreSQL.<br>- Feedback provided within <5s.<br>- Supports 10+ exercise types (e.g., Q&A, coding tasks). |

## Non-Functional Requirements
| ID  | Requirement Description                              | Priority | Acceptance Criteria                                      |
|-----|-----------------------------------------------------|----------|---------------------------------------------------------|
| NFR01 | **High Availability**: Ensure tool uptime and reliability. | High     | - 99% uptime via Cloudflare and Nginx.<br>- Downtime <10 minutes/month for maintenance. |
| NFR02 | **Security**: Protect user data and interactions.    | High     | - HTTPS via Cloudflare SSL/TLS.<br>- Encrypted PostgreSQL connections.<br>- No OWASP Top 10 vulnerabilities. |
| NFR03 | **Scalability**: Handle expected usage.              | Medium   | - Supports 10 concurrent users on Linode (4 GB RAM).<br>- API handles 10+ requests/second.<br>- Cloudflare caching for static content. |
| NFR04 | **Performance**: Ensure fast response times.         | High     | - LLM responses <2s for 95% of queries.<br>- Note export <5s.<br>- Responsive web interface for mobile/desktop. |
| NFR05 | **Maintainability**: Enable easy updates and monitoring. | Medium   | - Markdown updates via Git, auto-deployed by n8n.<br>- Monitoring via n8n and RustDesk.<br>- Documentation for all components. |

## Technical Constraints
- **Hardware**:
  - Proxmox: Hosts Ollama (`dockProd1`, 1 RTX 5060 Ti GPU) and PostgreSQL (`dockProd2`, 16 GB RAM).
  - Linode: Hosts FastAPI endpoints, limited by 4 GB RAM; offload LLM tasks to Proxmox.
- **Software**: Ollama, PostgreSQL, FastAPI, n8n, Cloudflare, integrated with AI-driven website (Hugo, Nginx).
- **Time**: ~150 hours for MVP (FR01-FR02, NFR01-NFR04) by December 2025, per **3.2 Project_Roadmap.md**.
- **Solo Operation**: Use n8n for automation, RustDesk for remote management.

## User Flows
- **Learner (Self)**:
  1. Access Learning Assistant via thinkheads.ai.
  2. Query resources (FR01), save notes (FR02), or complete exercises (FR03).
  3. Export notes as markdown for portfolio use.
- **Employer/Community**:
  1. View Learning Assistant demo on thinkheads.ai.
  2. Explore sample outputs (e.g., resource suggestions, notes) to assess technical skills.
- **RAG Integration**: Markdown documents and notes feed into Ollama for context-aware suggestions.

## RAG Integration
- **Usage**: Feeds into Meeting Roomâ€™s RAG pipeline for planning and resource curation.
- **Structure**: Consistent headers, tables, and metadata for parseability.
- **Storage**: Store in `/docs/projects/`, sync to Linode, embed in PostgreSQL for RAG queries.

## Success Metrics
- **Feature Completion**: Deploy MVP (FR01-FR02, NFR01-NFR04) by December 2025.
- **Learning**: Master RAG, LLM fine-tuning, and PostgreSQL by February 2026.
- **Portfolio**: Achieve 10+ employer views via X/LinkedIn by February 2026.
- **Performance**: <2s LLM response time, 99% uptime.
- **Engagement**: Contribute to 100+ unique visitors to thinkheads.ai by February 2026.